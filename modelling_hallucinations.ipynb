{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69fd9f2-3ee9-4f06-9f2d-15bb2fceee4f",
   "metadata": {},
   "source": [
    "# Modelling Hallucinations\n",
    "\n",
    "This notebook includes the results for part 2 of the \"Toy Models of Superposition Review\" assignment.\n",
    "\n",
    "A lot of the code has been taken from Anthropic's [toy models framework](https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb) and [FIT5215's assignment 2](https://colab.research.google.com/drive/1m0mh9Mk4-AKEhgAHRwQdl5mc0x7SF7Tv?usp=sharing) and has been repurposed for our specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d670a0d7-67c6-4e69-b7df-38deb76b838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from dataclasses import dataclass, replace\n",
    "import numpy as np\n",
    "import einops\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import words\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from transformers import BertTokenizer\n",
    "import ast\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee66dca9-dcf4-4de0-a2c8-15b7baeaf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed=42069):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_all()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = 'cuda'\n",
    "else:\n",
    "  DEVICE = 'cpu'\n",
    "DEVICE = torch.device(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165d299-4915-404a-b9f2-3a8e494ee244",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Using the `nltk` toolkit, we create our dataset using the following affixes:\n",
    "- un-\n",
    "- re-\n",
    "- -able\n",
    "- -ful\n",
    "- -ness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb57c69b-7cf3-44e7-be2c-9ccea0802528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 28611 words.\n"
     ]
    }
   ],
   "source": [
    "# Download the words corpus if not already downloaded\n",
    "nltk.download('words', quiet=True)\n",
    "\n",
    "# Get the list of English words\n",
    "english_words = words.words()\n",
    "\n",
    "# Define prefixes and suffixes\n",
    "prefixes = ['un', 're']\n",
    "suffixes = ['able', 'ful', 'ness']\n",
    "\n",
    "# Function to categorize a word\n",
    "def categorize_word(word):\n",
    "    prefix_match = next((prefix for prefix in prefixes if word.startswith(prefix)), None)\n",
    "    suffix_match = next((suffix for suffix in suffixes if word.endswith(suffix)), None)\n",
    "    \n",
    "    if prefix_match and suffix_match:\n",
    "        return [prefix_match, suffix_match]\n",
    "    elif prefix_match:\n",
    "        return prefix_match\n",
    "    elif suffix_match:\n",
    "        return suffix_match\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Process words and create dataset\n",
    "dataset = []\n",
    "for word in english_words:\n",
    "    category = categorize_word(word)\n",
    "    if category:\n",
    "        dataset.append([word, category])\n",
    "\n",
    "# Save to CSV\n",
    "with open('word_affixes_dataset.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['word', 'category'])  # Header\n",
    "    writer.writerows(dataset)\n",
    "\n",
    "print(f\"Dataset created with {len(dataset)} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235d93c-228e-4c9f-acda-f5b58b6fb8dc",
   "metadata": {},
   "source": [
    "## Defining classes\n",
    "\n",
    "We define the following classes:\n",
    "- `DataManager`: For loading the data and splitting it into the train, test and dual datasets\n",
    "- `BaseTrainer`: The trainer for training and evaluating the model\n",
    "- `Model`: The model we will use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be75638a-1637-4b29-b73b-7ab8140e5d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "        self.max_sentence_len = 0\n",
    "        self.str_words = list()\n",
    "        self.str_labels = list()\n",
    "        self.numeral_labels = list()\n",
    "        self.numeral_data = list()\n",
    "\n",
    "    def read_csv_data(self, file_path):\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Separate 'dual' class where category is more than one\n",
    "        dual_data = df[df[\"category\"].str.contains(\",\")]\n",
    "        non_dual_data = df[~df[\"category\"].str.contains(\",\")]\n",
    "\n",
    "        self.str_words = non_dual_data[\"word\"].tolist()\n",
    "        self.str_labels = non_dual_data[\"category\"].tolist()\n",
    "        self.dual_words = dual_data[\"word\"].tolist()\n",
    "        self.dual_labels = dual_data[\"category\"].tolist()\n",
    "\n",
    "        # Process max sentence length\n",
    "        for question in self.str_words + self.dual_words:\n",
    "            if self.max_sentence_len < len(str(question)):\n",
    "                self.max_sentence_len = len(str(question))\n",
    "\n",
    "        # Encode labels (excluding 'dual')\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.str_labels)\n",
    "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
    "        self.str_classes = le.classes_\n",
    "        self.num_classes = len(self.str_classes)\n",
    "\n",
    "        # Encode dual labels\n",
    "        dual_labels_temp = []\n",
    "        for label in self.dual_labels:\n",
    "            categories = ast.literal_eval(label)\n",
    "            encoded_cats = le.transform(categories)\n",
    "            dual_labels_temp.append(encoded_cats.tolist())\n",
    "        self.dual_labels = dual_labels_temp\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"\\nSample words and corresponding categories (non-dual)... \\n\")\n",
    "            print(self.str_words[:5])\n",
    "            print(self.str_labels[:5])\n",
    "            print(\"\\nSample dual words...\\n\")\n",
    "            print(self.dual_words[:5])\n",
    "            print(self.dual_labels[:5])\n",
    "\n",
    "    def manipulate_data(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        vocab = self.tokenizer.get_vocab()\n",
    "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "        self.idx2word = {i: w for w, i in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        num_seqs = []\n",
    "        dual_num_seqs = []\n",
    "\n",
    "        # Process non-dual words\n",
    "        for text in self.str_words:\n",
    "            text_seqs = self.tokenizer.tokenize(str(text))\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "            seq_tensor = torch.LongTensor(token_ids)\n",
    "            num_seqs.append(seq_tensor)\n",
    "\n",
    "        # Process dual words\n",
    "        for text in self.dual_words:\n",
    "            text_seqs = self.tokenizer.tokenize(str(text))\n",
    "            token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "            seq_tensor = torch.LongTensor(token_ids)\n",
    "            dual_num_seqs.append(seq_tensor)\n",
    "\n",
    "        if num_seqs:\n",
    "            self.numeral_data = pad_sequence(num_seqs, batch_first=True)\n",
    "            self.num_sentences, self.max_seq_len = self.numeral_data.shape\n",
    "\n",
    "        if dual_num_seqs:\n",
    "            self.dual_data = pad_sequence(dual_num_seqs, batch_first=True)\n",
    "            self.num_dual_sentences, self.max_dual_seq_len = self.dual_data.shape\n",
    "\n",
    "        # Ensure dual data has the same max sequence length as non-dual data\n",
    "        if hasattr(self, \"numeral_data\") and hasattr(self, \"dual_data\"):\n",
    "            max_len = max(self.max_seq_len, self.max_dual_seq_len)\n",
    "            self.numeral_data = F.pad(\n",
    "                self.numeral_data, (0, max_len - self.max_seq_len)\n",
    "            )\n",
    "            self.dual_data = F.pad(self.dual_data, (0, max_len - self.max_dual_seq_len))\n",
    "            self.max_seq_len = max_len\n",
    "            self.max_dual_seq_len = max_len\n",
    "\n",
    "    def tokenize_data(self, text):\n",
    "        text_seqs = self.tokenizer.tokenize(str(text))\n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "        seq_tensor = torch.LongTensor(token_ids)\n",
    "        return seq_tensor\n",
    "\n",
    "    def train_test_split(self, train_ratio=0.8):\n",
    "        # Split non-dual data\n",
    "        train_size = int(len(self.str_words) * train_ratio)\n",
    "\n",
    "        indices = list(range(len(self.str_words)))\n",
    "        random.shuffle(indices)\n",
    "\n",
    "        train_indices = indices[:train_size]\n",
    "        test_indices = indices[train_size:]\n",
    "\n",
    "        # Create datasets\n",
    "        train_data = [self.numeral_data[i] for i in train_indices]\n",
    "        train_labels = [self.numeral_labels[i] for i in train_indices]\n",
    "        test_data = [self.numeral_data[i] for i in test_indices]\n",
    "        test_labels = [self.numeral_labels[i] for i in test_indices]\n",
    "        dual_data = [self.dual_data[i] for i in range(len(self.dual_words))]\n",
    "        dual_labels = [self.dual_labels[i] for i in range(len(self.dual_words))]\n",
    "\n",
    "        # Create DataLoaders\n",
    "        self.train_loader = DataLoader(\n",
    "            TensorDataset(torch.stack(train_data), torch.tensor(train_labels)),\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        self.test_loader = DataLoader(\n",
    "            TensorDataset(torch.stack(test_data), torch.tensor(test_labels)),\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        self.dual_loader = DataLoader(\n",
    "            TensorDataset(torch.stack(dual_data), torch.tensor(dual_labels)),\n",
    "            batch_size=64,\n",
    "            shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af80187-f7cc-47da-b7af-152aa5ade9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, device):\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion  # the loss function\n",
    "        self.optimizer = optimizer  # the optimizer\n",
    "        self.train_loader = train_loader  # the train loader\n",
    "        self.device = device\n",
    "\n",
    "    # the function to train the model in many epochs\n",
    "    def fit(self, num_epochs):\n",
    "        self.num_batches = len(self.train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "            train_loss, train_accuracy = self.train_one_epoch()\n",
    "            print(\n",
    "                f\"{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}%\"\n",
    "            )\n",
    "\n",
    "    # train in one epoch, return the train_acc, train_loss\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / self.num_batches\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    # evaluate on a loader and return the loss and accuracy\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        loss = loss / len(loader)\n",
    "        return loss, accuracy\n",
    "\n",
    "    def evaluate_dual_labels(self, loader):\n",
    "        self.model.eval()\n",
    "        total_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                (\n",
    "                    inputs,\n",
    "                    dual_labels,\n",
    "                ) = data  # dual_labels contains lists of multiple possible labels per input\n",
    "                inputs = inputs.to(self.device)\n",
    "                dual_labels = [label_set.to(self.device) for label_set in dual_labels]\n",
    "\n",
    "                outputs = self.model(inputs)\n",
    "                loss = 0.0\n",
    "\n",
    "                # Compute loss for each sample based on the multiple labels\n",
    "                for i, label_set in enumerate(dual_labels):\n",
    "                    # Compute the loss against each of the possible labels\n",
    "                    per_sample_loss = torch.mean(\n",
    "                        torch.stack(\n",
    "                            [self.criterion(outputs[i], label) for label in label_set]\n",
    "                        )\n",
    "                    )\n",
    "                    loss += per_sample_loss.item()\n",
    "\n",
    "                total_loss += loss\n",
    "\n",
    "                # Get predictions\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # For each sample, check if the predicted label is in the set of dual labels\n",
    "                for i, label_set in enumerate(dual_labels):\n",
    "                    if predicted[i].item() in label_set.tolist():\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "\n",
    "        # Compute overall loss and accuracy\n",
    "        avg_loss = total_loss / len(loader)\n",
    "        accuracy = correct / total\n",
    "\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c72fa983-5e6c-4d42-8336-5b9cad776051",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    vocab_size: int\n",
    "    n_features: int\n",
    "    n_hidden: int\n",
    "    word2idx: dict\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.embed_size = config.n_features\n",
    "        self.word2idx = config.word2idx\n",
    "\n",
    "        self.embedding = nn.Embedding(config.vocab_size, self.embed_size)\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=self.embed_size,\n",
    "            out_channels=config.n_features,\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "        )\n",
    "\n",
    "        self.W = nn.Parameter(torch.empty((config.n_features, config.n_hidden)))\n",
    "        nn.init.xavier_normal_(self.W)\n",
    "        self.b_final = nn.Parameter(torch.zeros((config.n_features)))\n",
    "\n",
    "    def forward(self, x, return_hidden=False):\n",
    "        # features: [..., instance, n_features]\n",
    "        # W: [instance, n_features, n_hidden]\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1d(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "\n",
    "        hidden = x @ self.W\n",
    "        out = hidden @ self.W.T + self.b_final\n",
    "        out = F.relu(out)\n",
    "        if return_hidden:\n",
    "            return out, hidden\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62939a72-2103-4572-87ba-f3653199411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample words and corresponding categories (non-dual)... \n",
      "\n",
      "['abandonable', 'abasedness', 'abashedness', 'abatable', 'abdicable']\n",
      "['able', 'ness', 'ness', 'able', 'able']\n",
      "\n",
      "Sample dual words...\n",
      "\n",
      "['reachable', 'reactionariness', 'reactiveness', 'readable', 'readableness']\n",
      "[[3, 0], [3, 2], [3, 2], [3, 0], [3, 2]]\n"
     ]
    }
   ],
   "source": [
    "dm = DataManager()\n",
    "dm.read_csv_data('word_affixes_dataset.csv')\n",
    "dm.manipulate_data()\n",
    "dm.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a75cdc65-317c-4f82-a80e-2774013c0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 8]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dm.train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ce38b0c-7872-40b8-8691-532b43d6dc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    vocab_size=dm.vocab_size,\n",
    "    word2idx=dm.word2idx,\n",
    "    n_features=dm.num_classes,\n",
    "    n_hidden=2,\n",
    ")\n",
    "\n",
    "model = Model(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a81402-afe4-40e1-977d-8ec74d79c50f",
   "metadata": {},
   "source": [
    "## Training and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "596810f7-e57d-44d5-90e2-9a5f8f232c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "324/324 - train_loss: 1.3625 - train_accuracy: 46.5523%\n",
      "Epoch 2/100\n",
      "324/324 - train_loss: 1.0209 - train_accuracy: 58.7437%\n",
      "Epoch 3/100\n",
      "324/324 - train_loss: 0.8135 - train_accuracy: 67.3496%\n",
      "Epoch 4/100\n",
      "324/324 - train_loss: 0.6663 - train_accuracy: 74.9022%\n",
      "Epoch 5/100\n",
      "324/324 - train_loss: 0.5884 - train_accuracy: 79.6328%\n",
      "Epoch 6/100\n",
      "324/324 - train_loss: 0.5288 - train_accuracy: 82.3146%\n",
      "Epoch 7/100\n",
      "324/324 - train_loss: 0.4813 - train_accuracy: 84.6195%\n",
      "Epoch 8/100\n",
      "324/324 - train_loss: 0.4311 - train_accuracy: 85.4554%\n",
      "Epoch 9/100\n",
      "324/324 - train_loss: 0.3272 - train_accuracy: 89.4661%\n",
      "Epoch 10/100\n",
      "324/324 - train_loss: 0.2570 - train_accuracy: 91.1621%\n",
      "Epoch 11/100\n",
      "324/324 - train_loss: 0.2235 - train_accuracy: 92.0705%\n",
      "Epoch 12/100\n",
      "324/324 - train_loss: 0.2017 - train_accuracy: 92.7132%\n",
      "Epoch 13/100\n",
      "324/324 - train_loss: 0.1798 - train_accuracy: 93.6700%\n",
      "Epoch 14/100\n",
      "324/324 - train_loss: 0.1540 - train_accuracy: 95.3419%\n",
      "Epoch 15/100\n",
      "324/324 - train_loss: 0.1307 - train_accuracy: 96.1971%\n",
      "Epoch 16/100\n",
      "324/324 - train_loss: 0.1142 - train_accuracy: 96.7432%\n",
      "Epoch 17/100\n",
      "324/324 - train_loss: 0.1037 - train_accuracy: 97.0766%\n",
      "Epoch 18/100\n",
      "324/324 - train_loss: 0.0952 - train_accuracy: 97.3279%\n",
      "Epoch 19/100\n",
      "324/324 - train_loss: 0.0845 - train_accuracy: 97.6081%\n",
      "Epoch 20/100\n",
      "324/324 - train_loss: 0.0779 - train_accuracy: 97.7676%\n",
      "Epoch 21/100\n",
      "324/324 - train_loss: 0.0730 - train_accuracy: 97.8449%\n",
      "Epoch 22/100\n",
      "324/324 - train_loss: 0.0696 - train_accuracy: 97.9270%\n",
      "Epoch 23/100\n",
      "324/324 - train_loss: 0.0657 - train_accuracy: 98.0333%\n",
      "Epoch 24/100\n",
      "324/324 - train_loss: 0.0630 - train_accuracy: 98.0382%\n",
      "Epoch 25/100\n",
      "324/324 - train_loss: 0.0601 - train_accuracy: 98.0913%\n",
      "Epoch 26/100\n",
      "324/324 - train_loss: 0.0579 - train_accuracy: 98.1493%\n",
      "Epoch 27/100\n",
      "324/324 - train_loss: 0.0549 - train_accuracy: 98.1590%\n",
      "Epoch 28/100\n",
      "324/324 - train_loss: 0.0530 - train_accuracy: 98.2218%\n",
      "Epoch 29/100\n",
      "324/324 - train_loss: 0.0510 - train_accuracy: 98.2315%\n",
      "Epoch 30/100\n",
      "324/324 - train_loss: 0.0493 - train_accuracy: 98.2653%\n",
      "Epoch 31/100\n",
      "324/324 - train_loss: 0.0473 - train_accuracy: 98.2943%\n",
      "Epoch 32/100\n",
      "324/324 - train_loss: 0.0457 - train_accuracy: 98.3233%\n",
      "Epoch 33/100\n",
      "324/324 - train_loss: 0.0445 - train_accuracy: 98.3233%\n",
      "Epoch 34/100\n",
      "324/324 - train_loss: 0.0427 - train_accuracy: 98.3378%\n",
      "Epoch 35/100\n",
      "324/324 - train_loss: 0.0415 - train_accuracy: 98.3571%\n",
      "Epoch 36/100\n",
      "324/324 - train_loss: 0.0404 - train_accuracy: 98.3426%\n",
      "Epoch 37/100\n",
      "324/324 - train_loss: 0.0391 - train_accuracy: 98.3668%\n",
      "Epoch 38/100\n",
      "324/324 - train_loss: 0.0384 - train_accuracy: 98.3861%\n",
      "Epoch 39/100\n",
      "324/324 - train_loss: 0.0374 - train_accuracy: 98.3813%\n",
      "Epoch 40/100\n",
      "324/324 - train_loss: 0.0364 - train_accuracy: 98.4006%\n",
      "Epoch 41/100\n",
      "324/324 - train_loss: 0.0354 - train_accuracy: 98.4102%\n",
      "Epoch 42/100\n",
      "324/324 - train_loss: 0.0347 - train_accuracy: 98.4344%\n",
      "Epoch 43/100\n",
      "324/324 - train_loss: 0.0341 - train_accuracy: 98.4344%\n",
      "Epoch 44/100\n",
      "324/324 - train_loss: 0.0333 - train_accuracy: 98.4344%\n",
      "Epoch 45/100\n",
      "324/324 - train_loss: 0.0327 - train_accuracy: 98.4682%\n",
      "Epoch 46/100\n",
      "324/324 - train_loss: 0.0322 - train_accuracy: 98.4876%\n",
      "Epoch 47/100\n",
      "324/324 - train_loss: 0.0316 - train_accuracy: 98.4779%\n",
      "Epoch 48/100\n",
      "324/324 - train_loss: 0.0312 - train_accuracy: 98.5214%\n",
      "Epoch 49/100\n",
      "324/324 - train_loss: 0.0306 - train_accuracy: 98.5359%\n",
      "Epoch 50/100\n",
      "324/324 - train_loss: 0.0302 - train_accuracy: 98.5504%\n",
      "Epoch 51/100\n",
      "324/324 - train_loss: 0.0299 - train_accuracy: 98.5359%\n",
      "Epoch 52/100\n",
      "324/324 - train_loss: 0.0296 - train_accuracy: 98.5552%\n",
      "Epoch 53/100\n",
      "324/324 - train_loss: 0.0292 - train_accuracy: 98.5552%\n",
      "Epoch 54/100\n",
      "324/324 - train_loss: 0.0292 - train_accuracy: 98.5649%\n",
      "Epoch 55/100\n",
      "324/324 - train_loss: 0.0287 - train_accuracy: 98.5745%\n",
      "Epoch 56/100\n",
      "324/324 - train_loss: 0.0284 - train_accuracy: 98.5697%\n",
      "Epoch 57/100\n",
      "324/324 - train_loss: 0.0284 - train_accuracy: 98.5842%\n",
      "Epoch 58/100\n",
      "324/324 - train_loss: 0.0280 - train_accuracy: 98.5794%\n",
      "Epoch 59/100\n",
      "324/324 - train_loss: 0.0278 - train_accuracy: 98.5745%\n",
      "Epoch 60/100\n",
      "324/324 - train_loss: 0.0276 - train_accuracy: 98.5745%\n",
      "Epoch 61/100\n",
      "324/324 - train_loss: 0.0277 - train_accuracy: 98.5794%\n",
      "Epoch 62/100\n",
      "324/324 - train_loss: 0.0273 - train_accuracy: 98.5697%\n",
      "Epoch 63/100\n",
      "324/324 - train_loss: 0.0273 - train_accuracy: 98.5745%\n",
      "Epoch 64/100\n",
      "324/324 - train_loss: 0.0273 - train_accuracy: 98.5697%\n",
      "Epoch 65/100\n",
      "324/324 - train_loss: 0.0269 - train_accuracy: 98.5745%\n",
      "Epoch 66/100\n",
      "324/324 - train_loss: 0.0269 - train_accuracy: 98.5745%\n",
      "Epoch 67/100\n",
      "324/324 - train_loss: 0.0269 - train_accuracy: 98.5842%\n",
      "Epoch 68/100\n",
      "324/324 - train_loss: 0.0266 - train_accuracy: 98.5842%\n",
      "Epoch 69/100\n",
      "324/324 - train_loss: 0.0266 - train_accuracy: 98.5794%\n",
      "Epoch 70/100\n",
      "324/324 - train_loss: 0.0264 - train_accuracy: 98.5987%\n",
      "Epoch 71/100\n",
      "324/324 - train_loss: 0.0265 - train_accuracy: 98.5890%\n",
      "Epoch 72/100\n",
      "324/324 - train_loss: 0.0261 - train_accuracy: 98.6132%\n",
      "Epoch 73/100\n",
      "324/324 - train_loss: 0.0261 - train_accuracy: 98.6084%\n",
      "Epoch 74/100\n",
      "324/324 - train_loss: 0.0262 - train_accuracy: 98.6132%\n",
      "Epoch 75/100\n",
      "324/324 - train_loss: 0.0260 - train_accuracy: 98.6084%\n",
      "Epoch 76/100\n",
      "324/324 - train_loss: 0.0258 - train_accuracy: 98.6180%\n",
      "Epoch 77/100\n",
      "324/324 - train_loss: 0.0258 - train_accuracy: 98.6325%\n",
      "Epoch 78/100\n",
      "324/324 - train_loss: 0.0259 - train_accuracy: 98.6180%\n",
      "Epoch 79/100\n",
      "324/324 - train_loss: 0.0257 - train_accuracy: 98.6229%\n",
      "Epoch 80/100\n",
      "324/324 - train_loss: 0.0256 - train_accuracy: 98.6277%\n",
      "Epoch 81/100\n",
      "324/324 - train_loss: 0.0256 - train_accuracy: 98.6374%\n",
      "Epoch 82/100\n",
      "324/324 - train_loss: 0.0258 - train_accuracy: 98.6374%\n",
      "Epoch 83/100\n",
      "324/324 - train_loss: 0.0256 - train_accuracy: 98.6180%\n",
      "Epoch 84/100\n",
      "324/324 - train_loss: 0.0254 - train_accuracy: 98.6470%\n",
      "Epoch 85/100\n",
      "324/324 - train_loss: 0.0254 - train_accuracy: 98.6422%\n",
      "Epoch 86/100\n",
      "324/324 - train_loss: 0.0253 - train_accuracy: 98.6422%\n",
      "Epoch 87/100\n",
      "324/324 - train_loss: 0.0253 - train_accuracy: 98.6422%\n",
      "Epoch 88/100\n",
      "324/324 - train_loss: 0.0257 - train_accuracy: 98.6518%\n",
      "Epoch 89/100\n",
      "324/324 - train_loss: 0.0252 - train_accuracy: 98.6567%\n",
      "Epoch 90/100\n",
      "324/324 - train_loss: 0.0252 - train_accuracy: 98.6808%\n",
      "Epoch 91/100\n",
      "324/324 - train_loss: 0.0250 - train_accuracy: 98.6567%\n",
      "Epoch 92/100\n",
      "324/324 - train_loss: 0.0250 - train_accuracy: 98.6518%\n",
      "Epoch 93/100\n",
      "324/324 - train_loss: 0.0251 - train_accuracy: 98.6567%\n",
      "Epoch 94/100\n",
      "324/324 - train_loss: 0.0249 - train_accuracy: 98.6760%\n",
      "Epoch 95/100\n",
      "324/324 - train_loss: 0.0250 - train_accuracy: 98.6712%\n",
      "Epoch 96/100\n",
      "324/324 - train_loss: 0.0248 - train_accuracy: 98.6760%\n",
      "Epoch 97/100\n",
      "324/324 - train_loss: 0.0246 - train_accuracy: 98.6905%\n",
      "Epoch 98/100\n",
      "324/324 - train_loss: 0.0248 - train_accuracy: 98.6905%\n",
      "Epoch 99/100\n",
      "324/324 - train_loss: 0.0248 - train_accuracy: 98.7098%\n",
      "Epoch 100/100\n",
      "324/324 - train_loss: 0.0245 - train_accuracy: 98.7147%\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = BaseTrainer(model=model, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, device=DEVICE)\n",
    "trainer.fit(num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3e5099-f8d1-463f-a7f9-91869f44e251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         Accuracy\n",
      "------------  ----------\n",
      "Test set        0.970816\n",
      "Dual dataset    0.865062\n"
     ]
    }
   ],
   "source": [
    "_, test_accuracy = trainer.evaluate(dm.test_loader)\n",
    "_, dual_accuracy = trainer.evaluate_dual_labels(dm.dual_loader)\n",
    "\n",
    "table = [\n",
    "    [\"Test set\", test_accuracy],\n",
    "    [\"Dual dataset\", dual_accuracy],\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers=[\"Dataset\", \"Accuracy\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c484a-9141-4027-b2d2-4f22b9a20b2a",
   "metadata": {},
   "source": [
    "## Visualizing feature embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d62e635e-c521-4732-9c63-aa8bdbe0acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_intro_diagram(model, hiddens=None):\n",
    "  from matplotlib import colors  as mcolors\n",
    "  from matplotlib import collections  as mc\n",
    "  cfg = model.config\n",
    "  W = model.W.cpu().detach()\n",
    "  N = len(W[:,0])\n",
    "  sel = range(1)\n",
    "  # plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.viridis(model.importance[0].cpu().numpy()))\n",
    "  plt.rcParams['figure.dpi'] = 200\n",
    "  fig, ax = plt.subplots(1,len(sel), figsize=(2*len(sel),2))\n",
    "  colors = [mcolors.to_rgba(c)\n",
    "        for c in plt.rcParams['axes.prop_cycle'].by_key()['color']]\n",
    "  ax.scatter(W[:,0], W[:,1], c=colors[0:len(W[:,0])])\n",
    "  ax.set_aspect('equal')\n",
    "  ax.add_collection(mc.LineCollection(np.stack((np.zeros_like(W),W), axis=1), colors=colors))\n",
    "\n",
    "  if hiddens is not None:\n",
    "    activation = hiddens.cpu().detach().numpy()\n",
    "    ax.scatter(activation[0, 0], activation[0, 1], c='black', s=100)\n",
    "    \n",
    "    ax.add_collection(mc.LineCollection([[(0, 0), (activation[0, 0], activation[0, 1])]], \n",
    "                                        colors=['black'], \n",
    "                                        linewidths=2, \n",
    "                                        linestyle='--'))\n",
    "\n",
    "  z = 5\n",
    "  ax.set_facecolor('#FCFBF8')\n",
    "  ax.set_xlim((-z,z))\n",
    "  ax.set_ylim((-z,z))\n",
    "  ax.tick_params(left = True, right = False , labelleft = False ,\n",
    "              labelbottom = False, bottom = True)\n",
    "  for spine in ['top', 'right']:\n",
    "      ax.spines[spine].set_visible(False)\n",
    "  for spine in ['bottom','left']:\n",
    "      ax.spines[spine].set_position('center')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c4f51a2-b6d0-4d75-8bd2-9def1ee9c5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_intro_diagram(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0eb9dcc2-3fd4-443c-b646-62b16e61a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_from_word(word):\n",
    "    tokens = dm.tokenize_data(word).to(DEVICE)\n",
    "    outputs, hidden = model.forward(tokens.unsqueeze(0), return_hidden=True)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return predicted, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b3b6be40-8f20-4e17-8a02-7a879cc213fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"unreliable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2a8dadee-69c0-4d69-99f3-e63d9b3fe106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: able\n"
     ]
    }
   ],
   "source": [
    "out, acts = get_activation_from_word(word)\n",
    "plot_intro_diagram(model, acts)\n",
    "print(f\"Predicted class: {dm.str_classes[out]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
